import ast
import importlib
import os
import os.path as osp
import shutil
from abc import ABCMeta, abstractmethod
from ast import (
    AST,
    Attribute,
    Call,
    ClassDef,
    Constant,
    FunctionDef,
    Import,
    ImportFrom,
    Name,
    NodeTransformer,
    NodeVisitor,
    Subscript,
)
from collections import OrderedDict, defaultdict
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Sequence, TypeVar, Union

import astor
from astpretty import pprint  # for pdb debug

CODEGEN_PREFIX = '# Generated by CodeSlim\n'

REMOVE_NODE = None

_IMPORT_CACHE = ['torch', 'torch.nn']

T = TypeVar('T')

LIST_OR_ITEM = Union[T, List[T]]


def _is_file_exist(dir, filename):
    return osp.exists(osp.join(dir, filename))


def _get_file_name(file_path):
    file = osp.basename(file_path).split('.')[:-1]
    return '.'.join(file)


def _get_local_methods(parser: DefaultASTParser):
    local_methods = {}
    for name, func in parser._local_defs.items():
        if func.def_type == _DefType.Method:
            local_methods[name] = func
    return local_methods


def parse_file(filename: str):
    ext = os.path.splitext(filename)
    if ext != '.py':
        pass
    with open(filename, 'r') as f:
        source_code = f.read()
    return ast.parse(source_code)


def cd(target):
    prev = os.getcwd()
    os.chdir(os.path.expanduser(target))
    try:
        yield
    finally:
        os.chdir(prev)


class CodeGenerator:

    def generate(self):
        raise NotImplementedError()

    def _preprocess(self, file, parser):
        pass

    def _postprocess(self):
        pass

    def _generate_from_str(self,
                           filename,
                           contends: Optional[List[str]] = None):
        with open(filename, 'w', encoding='UTF-8') as f:
            f.writelines(CODEGEN_PREFIX)
            if contends:
                for c in contends:
                    f.writelines(c)

    def _generate_from_ast(self, filename, ast):
        source_code = astor.to_source(ast)
        with open(filename, 'w', encoding='UTF-8') as f:
            f.writelines(CODEGEN_PREFIX)
            f.write(source_code)

    def generate_init(self, target_path, force=False):
        if not force and _is_file_exist(target_path, '__init__.py'):
            raise RuntimeError('__init__.py exists!')
        path = osp.join(target_path, '__init__.py')
        self._generate_from_str(path)

    def rewrite_imports(self, ast, module_mapper):
        raise NotImplementedError()

    def copy_file(self, source_file, target_dir, force=False):
        if not force and _is_file_exist(target_dir, osp.basename(source_file)):
            raise RuntimeError(f'{source_file} exists!')
        shutil.copy(source_file, target_dir)

    def makedirs(self, path):
        os.makedirs(path, exist_ok=True)

    # Do we need to fotmat generated code?
    def format(self, file_path):
        pass


class Rewriter(NodeTransformer):

    def __init__(
        self,
        targets: Dict[str, Callable],
        pre_hooks: Optional[Dict[str, Callable]] = None,
        post_hooks: Optional[Dict[str, Callable]] = None,
    ):
        for name, func in targets.items():
            setattr(self, 'visit_' + name, func)

        self.pre_hooks = pre_hooks or {}
        self.post_hooks = post_hooks or {}

    def visit(self, node):
        node_name = node.__class__.__name__
        if node_name in self.pre_hooks:
            self.pre_hooks[node_name](node)
        if node is REMOVE_NODE:
            return node
        method = 'visit_' + node_name
        visitor = getattr(self, method, self.generic_visit)
        node = visitor(node)
        if node_name in self.post_hooks:
            node = self.post_hooks[node_name](node)
        return node


class _ClassVisitor(NodeVisitor):

    def __init__(self, cls_node):
        self.methods = {}
        self.visit(cls_node)

    def visit_FunctionDef(self, node: FunctionDef):
        self.methods[node.name] = node
        return self.generic_visit(node)


class ClassMerging:
    Eliminate = 1  # merge into one class inheriting from object
    KeepOne = 2  # merge into two class -- the lowest level class and base class.

    # all the methods, property will be patched to the highest level base class.
    def __init__(self, parser, base_parsers: Dict, class_name: str):
        self.parser = parser
        self.base_parsers = base_parsers
        self.rewriter = Rewriter({
            'FunctionDef': self._merge_methods,
            'Name': self._rewrite_name
        })
        self.cls_node = parser._local_defs[class_name].node
        self.methods = _ClassVisitor(self.cls_node).methods

    # TODO
    def _rewrite_super(self):
        pass

    def _merge_methods(self, node):
        if node.name not in self.methods:
            # astor.to_source do not use lineno, so just append it
            self.cls_node.body.append(node)
        return node

    def _rewrite_name(self, node):
        return node

    def _merge_property(self, node):
        pass

    def merge(self):
        for base_name, base_parser in self.base_parsers.items():
            self.cur_base = base_name
            base_node = base_parser._local_defs[base_name].node
            self.cls_node.bases = base_node.bases
            self.rewriter.visit(base_node)


class UnusedRemoval:
    pass


class InLine:
    pass


class FileLevelCodeGenerator(CodeGenerator):

    def __init__(
        self,
        target_dir: str,
        parser: Parser,
        # TODO(Asthestarsfalll): Support customize file structure
        module_mapper: Optional[Dict[str, str]] = None,
        custom_rewriter: Optional[Dict[str, Callable]] = None,
        class_merge_level: Optional[int] = None,
    ):
        self.target_dir = target_dir
        self.parsers = parser.get_parsers()
        self.module_mapper = module_mapper or {}
        if self.__class__.__name__ == 'FileLevelCodeGenerator' and class_merge_level is not None:
            raise ValueError(
                'File level code slim do not support for class merging.')
        if class_merge_level:
            for p in self.parsers.values():
                p.get_target_merge_class()
        self.merge_level = class_merge_level
        self.rewriter = self._build_rewriter(custom_rewriter)
        self.imports_info = self._get_imports_info(parser.relations)
        self.relation = parser.relations

    def _build_rewriter(self, custom_rewriter):
        rewrite_funcs = {
            'Import': self.rewrite_imports,
            'ImportFrom': self.rewrite_imports,
        }
        if custom_rewriter is not None:
            rewrite_funcs.update(custom_rewriter)
        return Rewriter(rewrite_funcs)

    def _get_imports_info(self, relation):
        extra_info = defaultdict(list)
        for file, target_file in relation.items():
            for f in target_file:
                extra_info[f].append(file)
        return extra_info

    def generate(self):
        self.makedirs(self.target_dir)
        with cd(self.target_dir):
            for file, parser in self.parsers.items():
                file_name = osp.basename(parser.file_name)
                # TODO(Asthestarsfalll): need to process __init__ file
                if file_name == '__init__.py':
                    continue
                self._preprocess(file, parser)
                self.rewriter.visit(parser.ast)
                self._postprocess()
                self._generate_from_ast(file_name, parser.ast)

    def rewrite_imports(self, node: Union[ImportFrom, Import]) -> AST:
        if isinstance(node, ImportFrom) and hasattr(node, 'is_target'):
            module_name = node.module
            if module_name in self.module_mapper:
                module_name = self.module_mapper[module_name]
            else:
                # FIXME(Asthestarsfalll): need automatically get the file where the imported module belongs to
                module_name = module_name.split('.')[-1]
                node.level = 0
            node.module = module_name

        return node


class SegmentCodeGenerator(FileLevelCodeGenerator):

    def _build_rewriter(self, custom_rewriter):
        rewrite_funcs = {
            'Import': self.rewrite_imports,
            'ImportFrom': self.rewrite_imports,
            'FunctionDef': self.rewrite_defs,
            'ClassDef': self.rewrite_defs,
        }
        if custom_rewriter is not None:
            rewrite_funcs.update(custom_rewriter)
        pre_hooks = {'ClassDef': self._classdef_hook}
        return Rewriter(rewrite_funcs, pre_hooks=pre_hooks)

    def _classdef_hook(self, node: ClassDef):
        if node.name not in self.class_merge_info:
            return node
        info = self.class_merge_info[node.name]
        rewrite_parsers = {k: self.parsers[info[k]] for k in info}
        self.base_parsers = rewrite_parsers
        ClassMerging(self.cur_parser, rewrite_parsers, node.name).merge()
        return REMOVE_NODE

    def _analyze_local_calls(self, parser):
        calls = parser._calls
        defs = parser._local_defs
        local_used = []
        # TODO(Asthestarsfalll): reduce the size of calls
        if calls and defs:
            # TODO(Asthestarsfalll): need more logic to tackle complex situation.
            for name, call in calls.items():
                if name in defs:
                    local_used.append(name)
        return local_used

    def _rewrite_class_imports(self, node):
        # FIXME
        if isinstance(node, ImportFrom):
            name = node.names[0].asname or node.names[0].name
            if name in self.base_parsers:
                return REMOVE_NODE
        else:
            raise NotImplemented
        return node

    def _preprocess(self, file, parser):
        merge_class = parser._to_merge_classes
        target_files = defaultdict(OrderedDict)

        for path in self.relation[file]:
            p = self.parsers[path]
            for m, bases in merge_class.items():
                for base in bases:
                    if base in p._local_defs:
                        target_files[m][base] = path

        extern_uesd = []
        for i in self.imports_info[file]:
            p = self.parsers[i]
            extern_uesd += p.get_target_import_names()
        self.extern_used = extern_uesd
        self.local_used = self._analyze_local_calls(parser)
        self.class_merge_info = target_files
        self.cur_parser = parser

    def _postprocess(self):
        rewriter = Rewriter({
            'ImportFrom': self._rewrite_class_imports,
            'Import': self._rewrite_class_imports,
        })
        rewriter.visit(self.cur_parser.ast)

    def rewrite_defs(self, node: Union[FunctionDef, ClassDef]):
        if node.name not in self.extern_used and node.name not in self.local_used:
            return REMOVE_NODE
        return node


class EndPoint(metaclass=ABCMeta):
    __target__ = ['file_path']

    @abstractmethod
    # It seems that we only need to check file path(s)?
    def __call__(self, file_path):
        pass


class BuiltinEndPoint(EndPoint):

    def __init__(self):
        self.builtins = list(globals()['__builtins__'].keys())

    def __call__(self, module_name):
        return module_name in self.builtins


class LocalEndPoint(EndPoint):

    def __init__(self, local_dir):
        self.local_dir = os.path.dirname(os.path.abspath(local_dir))

    def __call__(self, file_path):
        file_abs_path = os.path.abspath(file_path)
        return os.path.commonprefix([file_abs_path,
                                     self.local_dir]) != self.local_dir


class ExceptEndPoint(LocalEndPoint):
    __target__ = ['file_path', 'module_name']

    def __init__(self, local_dir, excepts):
        if isinstance(excepts, str):
            excepts = [excepts]
        self.excepts = excepts
        super().__init__(local_dir)

    def __call__(self, file_path, module_name):
        if module_name in self.excepts:
            return False
        else:
            return super().__call__(file_path)


class EndPointManager:
    INCOMPATIBLE = [(LocalEndPoint, ExceptEndPoint)]

    def __init__(self, endpoints: Union[EndPoint, List[EndPoint]]):
        if not isinstance(endpoints, list):
            endpoints = [endpoints]
        endpoint_types = [type(i) for i in endpoints]
        for pair in EndPointManager.INCOMPATIBLE:
            if pair[0] in endpoint_types and pair[1] in endpoint_types:
                raise ValueError(f'Imcompatible endpoints: {pair}')
        self.endpoints = endpoints

    @classmethod
    def add_imcompatible_pair(cls, pair):
        assert len(pair) == 2
        cls.INCOMPATIBLE.append(pair)

    def check(self, local):
        for endpoint in self.endpoints:
            kwargs = {k: local[k] for k in endpoint.__target__}
            if endpoint(**kwargs):
                return True
        return False


class Entry(metaclass=ABCMeta):

    @classmethod
    def build(cls, *args):
        return cls(*args)

    @abstractmethod
    def convert_to_ast(self, entries):
        pass

    @abstractmethod
    def get_cache(self):
        pass

    def __iter__(self):
        for file, ast in zip(self.entries, self.asts):
            yield file, ast


class FileEntry(Entry):

    def __init__(self, entry_files: Union[str, Sequence[str]]) -> None:
        entries = [entry_files] if isinstance(entry_files,
                                              str) else entry_files
        self.entries = [os.path.abspath(i) for i in entries]
        self.asts = self.convert_to_ast(self.entries)

    def convert_to_ast(self, entries):
        return [parse_file(f) for f in entries]

    def get_cache(self):
        return self.entries


class StringEntry(Entry):
    pass


class SegmentEntry(Entry):
    pass


class ClassEntry(SegmentEntry):

    def __init__(self, class_nodes: ClassDef):
        self.entries = class_nodes
        self.ast = self.convert_to_ast(class_nodes)

    def convert_to_ast(self, entries):
        pass


class _ImportNode:
    node: Union[ImportFrom, Import]
    import_name: str
    module: str
    alias_name: Optional[str]
    is_target: bool = False

    def _parse_module(self, endpoints):
        module_name = self.module
        # need cache to prevent some heavy imports?
        try:
            imported_module = importlib.import_module(module_name)
            assert imported_module is not None
            if not hasattr(imported_module, '__file__'):
                return None
            file_path = imported_module.__file__
        except ModuleNotFoundError:
            # just a workaround for relative import
            # should find some other methods.
            with cd('.' * self.node.level):
                file_path = os.path.join(
                    os.getcwd(),
                    module_name.replace('.', os.sep) + '.py')
            if not os.path.exists(file_path):
                raise RuntimeError(f'Cannot import module {module_name}')
        if not endpoints.check(locals()):
            # FIXME (Asthestarsfalll): may produce inconsistent results due to some unknown reasons.
            # ugly patch
            self.node.is_target = True
            self.is_target = True
            return file_path


class _CallNode:
    name: str
    trace_info: List[str]


class _DefType(Enum):
    Function = 0
    Class = 1
    Method = 2


class _DefNode:

    def __init__(
        self,
        node: Union[FunctionDef, ClassDef],
        def_type: _DefType,
        parent: Optional[str] = None,
        bases: Optional[str] = None,
        metas: Optional[str] = None,
    ) -> None:
        if not isinstance(node, (FunctionDef, ClassDef)):
            raise TypeError()
        self.name = node.name
        self.def_type = def_type
        self.parent = parent
        self.node = node
        self.bases = bases
        self.metas = metas

    def __repr__(self) -> str:
        return f'_DefNode(name={self.name}, bases={self.bases}, self.metas={self.metas})'


class _PassController:

    def __init__(self) -> None:
        self.attached = []

    def attach(self, inp: Any) -> None:
        self.attached.append(id(inp))

    def detach(self, node: Any) -> None:
        self.attached.remove(id(node))

    def __call__(self, inp: Any) -> bool:
        if id(inp) in self.attached:
            self.detach(inp)
            # do pass
            return True
        return False


class DefaultASTParser(NodeVisitor):

    def __init__(self, ast: AST, endpoints: EndPointManager, file_name: str):
        self.ast = ast
        self.endpoints = endpoints
        self.file_name = file_name
        self.file_path = os.path.dirname(file_name)
        self._pass_controller = _PassController()
        # store imported modules, functions, classes and variables
        # FIXME(Asthestarsfalll): handle alias of the imported, as well as functions.partial...
        self._imports: Dict[str, _ImportNode] = {}
        self._uncertain_imports: List[_ImportNode] = []
        self._local_defs: OrderedDict[str, _DefNode] = OrderedDict()
        self._calls: Dict[str, _CallNode] = {}
        self._to_merge_classes: Optional[Dict] = {}
        self.visit(self.ast)

    def get_import_path(self):
        import_path = [
            i._parse_module(self.endpoints) for i in self._imports.values()
        ]
        return [i for i in import_path if i]

    def get_target_import_names(self):
        list(self._imports.keys())
        return [i for i, v in self._imports.items() if v.is_target]

    def get_target_merge_class(self):
        cls_names = {}
        for name, node in self._local_defs.items():
            if node.def_type == _DefType.Class and node.bases:
                # FIXME
                new_bases = [i for i in node.bases if i in self._imports]
                node.bases = new_bases or None
                if new_bases:
                    cls_names[name] = new_bases
        self._to_merge_classes = cls_names

    def info(self):
        print('Imports:\n', self._imports)
        print('Calls:\n', self._calls)
        print('Uncertain:\n', self._uncertain_imports)
        print('LocalDef:\n', self._local_defs)

    def visit(self, node):
        if not self._pass_controller(node):
            method = 'visit_' + node.__class__.__name__
            visitor = getattr(self, method, None)
            if visitor:
                visitor(node)
        return self.generic_visit(node)

    # Do not support for the case that directly import local module for now.
    # This requires analyzing the call of function/class,
    # and get the submodule/file where the function/class belong to.
    def _visit_import(self, node: Union[Import, ImportFrom]):
        import_names = node.names
        names = [i.asname or i.name for i in import_names]
        is_import_from = isinstance(node, ImportFrom)
        for name, import_name in zip(names, import_names):
            if not is_import_from:
                module_name = import_name.name
            else:
                module_name = node.module
            import_node = _ImportNode(node, name, module_name,
                                      import_name.asname)
            if name != '*':
                # FIXME(Asthestarsfalll): add some code to handle overridden imports.
                # TODO(Asthestarsfalll): use endpoint to sign the target imports and the others,
                #       so we can reduce the size of self._calls
                self._imports[name] = import_node
            else:
                self._uncertain_imports.append(import_node)

    visit_Import = _visit_import
    visit_ImportFrom = _visit_import

    def visit_FunctionDef(self, node: FunctionDef):
        # Maybe we don't need to store inner function
        self._local_defs[node.name] = _DefNode(node, _DefType.Function)

    def visit_ClassDef(self, node: ClassDef):
        for func in node.body:
            if isinstance(func, FunctionDef):
                def_node = _DefNode(node, _DefType.Method, node.name)
                self._local_defs[func.name] = def_node
                self._pass_controller.attach(func)

        # FIXME(Asthestarsfalll): support Attribute, class A(a.B)
        bases = []
        for base in node.bases:
            trace_info = []
            self._get_chained_name(base, trace_info)
            if trace_info:
                trace_info.reverse()
                bases.append(''.join(trace_info))
        self._local_defs[node.name] = _DefNode(node,
                                               _DefType.Class,
                                               bases=bases)

    def _get_chained_name(self, node, trace_info):
        if isinstance(node, Attribute):
            trace_info.append(node.attr)
            trace_info.append('.')
            node = node.value
            return self._get_chained_name(node, trace_info)
        elif isinstance(node, Call):
            self._pass_controller.attach(node)
            node = node.func
            trace_info.append('()')
            return self._get_chained_name(node, trace_info)
        elif isinstance(node, Subscript):
            idx = node.slice.value
            if hasattr(idx, 'value'):
                idx = idx.value
            elif hasattr(idx, 'id'):
                idx = idx.id
            else:
                raise RuntimeError()
            trace_info.append(f'[{idx}]')
            return self._get_chained_name(node.value, trace_info)
        elif isinstance(node, Constant):
            node.id = trace_info[-1]
            return node
        elif isinstance(node, Name):
            trace_info.append(node.id)
            return node
        else:
            raise NotImplementedError(f'Unsupported type: {type(node)}')

    # damn it! Need to find some way to simplify those chained cases:
    # self.xxx[0][0].xx()
    # Maybe just store the whole Call Node
    # and analyze when need
    # We only need this when import * ?
    # So currently we don't need this
    def visit_Call(self, node: Call):
        """
        get the chained Function/Class Call:
            self.funcs[0]() -> self.funcs[0]
            self.aa.bb.cc[a].aa() -> self.aa.bb.cc[a].aa
        """
        func = node.func
        trace_info = []
        func = self._get_chained_name(func, trace_info)

        name = func.id
        if trace_info:
            trace_info.reverse()
            name = ''.join(trace_info)
        # if name not in self._local_defs:
        # just build them, and clean it after whole parse stage
        # prevent some issues caused by visit order (maybe)
        self._calls[name] = _CallNode(name, trace_info)

    # for getattr, but it also will be caught by visit_Call
    # maybe not need
    def visit_Str(self, node: Constant):
        pass

    def print(self):
        pprint(self.ast)


class Parser:

    def __init__(self,
                 entry: Entry,
                 endpoints=None,
                 parser_type=DefaultASTParser):
        self.cache = set(*entry.get_cache())
        if endpoints is None:
            endpoints = LocalEndPoint(os.path.commonprefix(list(self.cache)))
        self.entry = entry
        self.parser_type = parser_type
        self.endpoints = EndPointManager(endpoints)
        self.ast_parsers = self._build_parsers(self.entry)
        self.relations = defaultdict(list)
        self.parse()

    def _build_parsers(self, entry):
        parsers = {}
        for file, ast in entry:
            parsers[file] = self.parser_type(ast, self.endpoints, file)
        return parsers

    def parse(self):
        temp = list(self.ast_parsers.values())
        module_path = []

        def _update_path():
            module_path.clear()
            for i in temp:
                # for some local imports
                with cd(i.file_path):
                    paths = set(i.get_import_path())
                self.relations[os.path.join(i.file_path,
                                            i.file_name)].extend(paths)
                for p in paths:
                    if p not in self.cache:
                        module_path.append(p)
                        self.cache.add(p)

        _update_path()
        while len(module_path) > 0:
            # new_entry = [self.entry.build(p) for p in module_path]
            entry = self.entry.build(module_path)
            parsers = self._build_parsers(entry)
            temp = list(parsers.values())
            self.ast_parsers.update(parsers)
            _update_path()

    def info(self):
        for file, parser in self.ast_parsers.items():
            print(f'----------{file}----------')
            parser.info()

    def get_parsers(self):
        return self.ast_parsers


class AutoSlim:
    FileLevel = FileLevelCodeGenerator
    SegmentLevel = SegmentCodeGenerator
    File = FileEntry
    String = StringEntry
    Eliminate = ClassMerging.Eliminate
    KeepOne = ClassMerging.KeepOne

    def __init__(
        self,
        entries: LIST_OR_ITEM[str],
        target_dir: str,
        refactor_info: Optional[Dict[str, str]] = None,
    ):
        self.entries = entries
        self.target_dir = target_dir
        self._mode = AutoSlim.FileLevel
        self._refactor_info = refactor_info or {}
        # Maybe we can name this O1 like optimization of gcc hh
        self._merge_class = None
        self._entry_type = FileEntry

    def mode(self, mode):
        self._mode = mode
        return self

    def merge_class(self, merge_level):
        self._merge_class = merge_level
        return self

    def entry_type(self, type):
        self._entry_type = type
        return self

    def generate(self):
        entry = self._entry_type(self.entries)
        parser = Parser(entry)
        codegen = self._mode(self.target_dir,
                             parser,
                             class_merge_level=self._merge_class)
        codegen.generate()
        return self
